% ==========================================================================================================
% [GD, MD, DISP] = nk_MLOptimizer_ParamAnnealer(GD, MD, DISP, Ps, Params_desc, ... 
%                                           mapY, algostr, f, d, npreml, nclass, batchflag, PsSel, combcell) 
% ==========================================================================================================     
% DESCRIPTION: % This function implements a simulated annealing procedure to search the 
% hyperparameter space defined in Ps. For each label (in multi‐label mode), 
% an initial candidate is chosen, and then iterative perturbations (neighbors) 
% are generated by moving one index up or down in the candidate grid. 
% If the change implies a different preprocessing hyperparameter setting 
% (i.e. a change in the last npreml entries of the candidate), new preprocessed 
% data are retrieved via nk_MLOptimizer_ExtractDimMat and new feature subsets are 
% computed via nk_CreateSubSets. 
%
% The candidate’s performance is evaluated on the CV partitions using nk_CVPermFold, 
% and the candidate is accepted based on the Boltzmann acceptance rule. 
% After a fixed number of iterations, the best candidate is selected and its results 
% are transferred to the GD and MD containers via nk_GridSearchHelper. 
%
% INPUTS: 
%   GD : Results container. 
%   MD : Model container. 
%   DISP : Display structure for reporting progress. 
%   Ps : Cell array of parameter combinations (per binary predictor). 
%   Params_desc : Cell array of parameter descriptions (per binary predictor). 
%   mapY : Structure containing CV1 training/test data. 
%   algostr : String describing the ML algorithm. 
%   f, d : Current outer (CV2) permutation and fold. 
%   npreml : Number of preprocessing hyperparameters (at end of candidate). 
%   nclass : Number of binary classifiers/predictors. 
%   batchflag : Batch mode flag. 
%   PsSel : (Optional) Previously selected parameter nodes (unused here; pass [] if not available). 
%   combcell : Flag indicating that Ps entries are stored as a cell array. 
% 
% OUTPUTS: % GD : Updated results container. 
%   MD : Updated model container. 
%   DISP : Updated display structure. 
% 
% GLOBAL VARIABLES: 
%   CV, MULTILABEL, CVPOS 
% =========================================================================
% (c) Nikolaos Koutsouleris, 05/2024

function [GD, MD, DISP] = nk_MLOptimizer_ParamAnnealer(GD, MD, DISP, Ps, Params_desc, mapY, algostr, f, d, npreml, nclass, ngroups, batchflag, PsSel, combcell) 

global VERBOSE CV GRD SVM MULTILABEL CVPOS

% Number of parameter combinations for the first classifier. 
nPs = size(Ps{1},1);

% push current CV2 partition to global 
CVPOS.CV2p = f;
CVPOS.CV2f = d;
 
if npreml > -1 
    if combcell 
        pp = unique(cell2mat(Ps{1}(:, end-npreml:end)), 'rows', 'stable'); 
    else 
        pp = unique(Ps{1}(:, end-npreml:end), 'rows', 'stable'); 
    end 
end

% Determine whether higher or lower performance is better performance
 [~, ~, ~, ~, ~, minmaxfl, evalop] = nk_ReturnEvalOperator(SVM.GridParam);
evalop = str2func(evalop);
if minmaxfl == 1
    dir = 1;  % Maximization (e.g., Balanced Accuracy)
else
    dir = -1; % Minimization (e.g., MAE)
end

% Determine the number of labels (multi-label mode). 
nl = nk_GetLabelDim(MULTILABEL);

tElapsedSum = 0; tic; 
if nPs > 1
    fprintf('\n === Performing simulated annealing hyperparameter optimization === \n'); 
else 
    fprintf('\n'); 
end
if ~isfield(DISP,'vizHandles'), DISP.vizHandles = []; end
if ~isfield(DISP, 'visited'), DISP.visited = []; end

% Parameter to control maximum jump size at initial temperature.
max_initial_jump = min(nPs, GRD.OptMode.SimAneal.max_initial_jump);  % For example, allow up to X index jumps at T=1.

% Probability for a completely random jump.
random_jump_prob = GRD.OptMode.SimAneal.random_jump_prob; 

% Loop over each label. 
for curlabel = 1:nl 

    % ----- Set simulated annealing parameters -----
    T = GRD.OptMode.SimAneal.T;         % Initial temperature.
    alpha = GRD.OptMode.SimAneal.alpha;  % Cooling factor.
    max_iter = min(GRD.OptMode.SimAneal.max_iter, nPs); % maximum iterations not exceeding nPs.
    
    MULTILABEL.curdim = curlabel;
    labelstr = ''; 
    idxPs = false(nPs,1);

    if MULTILABEL.flag
        if nl>1
            labelstr = sprintf('Label #%g: %s | ', MULTILABEL.sel(curlabel), MULTILABEL.desc{MULTILABEL.sel(curlabel)});
        else
            labelstr = sprintf('Label %s | ', MULTILABEL.desc{MULTILABEL.sel(curlabel)});
        end
    end
        
    % --- (Optional) Restrict candidate selection based on PsSel ---
    if ~exist('PsSel', 'var') || isempty(PsSel)
        PiSel = true(nPs, nclass);
    else
        PiSel = false(nPs, nclass);
        for curclass = 1:nclass
            % PsSel is assumed to be a cell array: PsSel{curclass}{curlabel}.SelNodes is a logical vector.
            PiSel(:, curclass) = PsSel{curclass}{curlabel}.SelNodes;
        end
    end
    
    % --- Initialize candidate ---
    % Randomly choose an initial candidate index that is allowed.
    valid_indices = find(all(PiSel, 2));
    if isempty(valid_indices)
        error('No valid hyperparameter combinations found per PsSel restrictions.');
    end
    current_index = valid_indices(randi(numel(valid_indices)));
    
    % Define cPs for the current candidate.
    cPs = cell(nclass,1);
    for curclass = 1:nclass
        DISP.P{curclass} = Ps{curclass}(current_index,:);
        cPs{curclass} = nk_PrepMLParams(Ps{curclass}, Params_desc{curclass}, current_index);
    end

    % Retrieve the preprocessing hyperparameter vector for current candidate.
    if npreml > -1
        if combcell
            curr_preproc = cell2mat(Ps{1}(current_index, end-npreml:end));
        else
            curr_preproc = Ps{1}(current_index, end-npreml:end);
        end
        [~, curr_preproc_index] = ismember(curr_preproc, pp, 'rows');
    else
        curr_preproc_index = 1;
    end

    % Retrieve preprocessed data and filtered subsets.
    mapYi = nk_MLOptimizer_ExtractDimMat(mapY, curr_preproc_index, cPs);
    FilterSubSets = nk_CreateSubSets(mapYi);
    
    % Evaluate the first candidate.
    pltcnt = 1; pltmax = max_iter;
    pltperc = pltcnt*100/pltmax ;
    DISP.pltperc = pltperc;
    
    [CV1perf, CV2perf, models] = nk_CVPermFold(mapYi, nclass, ngroups, cPs, FilterSubSets, batchflag);
    tElapsed = toc; tElapsedSum = tElapsedSum+tElapsed; 
    elaps = sprintf('\t%1.2f sec.',tElapsed);
    % Prepare NM Optimization viewer info
    DISP.s = sprintf('%s | %s%s\nCV2 [ %g, %g ] => %4g/%4g iterations => %1.1f%% [Simulated annealing]', ...
            elaps, labelstr, algostr, f, d , pltcnt, pltmax, pltperc);
    [GD, MD, DISP] = nk_GridSearchHelper(GD, MD, DISP, current_index, nclass, ngroups, CV1perf, CV2perf, models);
    if isfield(CV1perf,'detrend'), GD.Detrend{current_index} = CV1perf.detrend; end
    GD = nk_GenVI(mapYi, GD, CV, f, d, nclass, current_index, curlabel);
    current_cost = GD.TR(current_index);
    best_index = current_index;
    best_cost = current_cost;
    best_cPs = cPs;
    best_mapYi = mapYi;
    best_FilterSubSets = FilterSubSets;
    
    entry.index = current_index;
    entry.cost = current_cost;
    entry.CV1 = GD.TR(current_index);
    entry.CV2 = GD.TS(current_index);
    DISP.visited = [DISP.visited; entry];

    % Caching to save time
    idxPs(current_index) = true;
    
    reheat_iter = 0;

    % Main simulated annealing loop.
    for iter = 1:max_iter
    	
        tic
        % Determine variable step size based on temperature.
         % With a small probability, choose a random candidate to enhance exploration.
        if rand < random_jump_prob
            neighbor_index = valid_indices(randi(numel(valid_indices)));
        else
            % Otherwise, determine variable step size based on temperature.
            max_step = max(round(T * max_initial_jump), 1);
            step = randi(max_step);
            if rand < 0.5
                step = -step;
            end
            neighbor_index = current_index + step;
            neighbor_index = max(1, min(nPs, neighbor_index));
        end
        
        % Prepare neighbor candidate parameters.
        for curclass = 1:nclass
            DISP.P{curclass} = Ps{curclass}(neighbor_index,:);
            neighbor_cPs{curclass} = nk_PrepMLParams(Ps{curclass}, Params_desc{curclass}, neighbor_index);
        end
        
        % Retrieve neighbor's preprocessing hyperparameter vector.
        if npreml > -1
            if combcell
                neighbor_preproc = cell2mat(Ps{1}(neighbor_index, end-npreml:end));
            else
                neighbor_preproc = Ps{1}(neighbor_index, end-npreml:end);
            end
            [~, neighbor_preproc_index] = ismember(neighbor_preproc, pp, 'rows');
        else
            neighbor_preproc_index = 1;
        end

        if neighbor_preproc_index ~= curr_preproc_index || (~exist('mapYi','var') || isempty(mapYi))
            neighbor_mapYi = nk_MLOptimizer_ExtractDimMat(mapY, neighbor_preproc_index, neighbor_cPs);
            neighbor_FilterSubSets = nk_CreateSubSets(neighbor_mapYi);
        else
            neighbor_mapYi = mapYi;
            neighbor_FilterSubSets = FilterSubSets;
        end
  
        % Evaluate the neighbor candidate.
        pltcnt = iter+1;
        pltperc = pltcnt * 100/pltmax;
        DISP.pltperc = pltperc;

        % Compute only if cache is not available.
        if ~idxPs(neighbor_index) 
            
            [CV1perf_neighbor, CV2perf_neighbor, models_neighbor] = nk_CVPermFold(neighbor_mapYi, nclass, ngroups, neighbor_cPs, neighbor_FilterSubSets, batchflag);
            tElapsed = toc; tElapsedSum = tElapsedSum+tElapsed; 
            elaps = sprintf('\t%1.2f sec.',tElapsed);

            % Prepare NM Optimization viewer info
            DISP.s = sprintf('%s | %s%s\nCV2 [ %g, %g ] => %4g/%4g iterations => %1.1f%% [Simulated Annealing: T=%1.4f]', ...
                    elaps, labelstr, algostr, f, d , pltcnt, pltmax, pltperc, T);
            [GD, MD, DISP] = nk_GridSearchHelper(GD, MD, DISP, neighbor_index, nclass, ngroups, CV1perf_neighbor, CV2perf_neighbor, models_neighbor);
            if isfield(CV1perf,'detrend'), GD.Detrend{neighbor_index} = CV1perf.detrend; end
            GD = nk_GenVI(neighbor_mapYi, GD, CV, f, d, nclass, neighbor_index, curlabel);

        end            
        neighbor_cost = GD.TR(neighbor_index);
        idxPs(neighbor_index) = true;

        % Compute acceptance probability.
        delta_cost = dir * ( neighbor_cost - current_cost );
        if delta_cost > 0
            accept_prob = 1;
        else
            accept_prob = exp(delta_cost / T);
        end
        
        % Accept neighbor candidate with computed probability.
        if rand < accept_prob
            current_index = neighbor_index;
            current_cost = neighbor_cost;
            % Update current candidate outputs.
            mapYi =  neighbor_mapYi ;
            FilterSubSets = neighbor_FilterSubSets;
            cPs = neighbor_cPs;
            curr_preproc_index = neighbor_preproc_index;
            reheat_iter = 0;
        else
            reheat_iter = reheat_iter + 1;
        end
        
        % Update best candidate if current is better.
        if evalop(current_cost, best_cost)
            best_cost = current_cost;
            best_index = current_index;
            best_cPs = cPs;
            best_mapYi = mapYi;
            best_FilterSubSets = FilterSubSets;
        end

        entry.index = neighbor_index;
        entry.cost = neighbor_cost;
        entry.CV1 = GD.TR(neighbor_index);
        entry.CV2 = GD.TS(neighbor_index);
        DISP.visited = [DISP.visited; entry];

        % After the candidate evaluation and before updating the temperature:
        if reheat_iter > GRD.OptMode.SimAneal.reheating_iter % if more than 10 iterations have passed
            % If no improvement in the last 10 iterations (you could track this via a counter),
            % then reheat:
            if dir * (best_cost - current_cost) < 1e-4  % threshold for improvement (adjust as needed)
                T = T * GRD.OptMode.SimAneal.reheating_alpha;  % reheat by increasing temperature by 20%
                if VERBOSE, fprintf('\tReheating: New T = %1.4f!', T); end
            else
                T = T * alpha;  % normal cooling
            end
            reheat_iter = 0;
        else
            T = T * alpha;  % normal cooling for early iterations
        end
        
        if VERBOSE
            % Display visited indices analysis plots.
            nk_VisVisitedIdx(DISP.visited , Ps{1}, Params_desc{1});
            % Update display message.
            currentHP = mat2str(Ps{1}(current_index,:));
            bestHP = mat2str(Ps{1}(best_index,:));
            fprintf('\n%sIteration %g/%g, Current Perf = %1.4f, Best Perf = %1.4f, T = %1.4f\nCurrent HP: %s\nBest HP: %s',...
                labelstr, iter, max_iter, current_cost, best_cost, T, currentHP, bestHP);
        end

    end
    % ----- End of simulated annealing loop for current label -----
    
    % Store best candidate parameters for the current label.
    for curclass = 1:nclass
        DISP.P{curclass} = Ps{curclass}(best_index, :);
    end
    % Re-evaluate the best candidate on the CV partitions.
    [CV1perf_final, CV2perf_final, models_final] = nk_CVPermFold(best_mapYi, nclass, ngroups, best_cPs, best_FilterSubSets, batchflag);
    % Update the overall results (GD and MD) using the helper function.
    [GD, MD, DISP] = nk_GridSearchHelper(GD, MD, DISP, best_index, nclass, ngroups, CV1perf_final, CV2perf_final, models_final);
    
    if isfield(CV1perf,'detrend'), GD.Detrend{best_index} = CV1perf.detrend; end
    % Create variate mask according to selected features
    GD = nk_GenVI(best_mapYi, GD, CV, f, d, nclass, best_index, curlabel);

end
DISP.visited = [];

fprintf('\n');fprintf('CV2 [%g, %g]: OPTIMIZATION COMPLETED IN %1.2f SEC ', ...
    f, d, tElapsedSum)